> 구글 같은 웹 검색엔진은 일련의 검색어를 받아 그와 관련된 웹페이지 목록을 반환한다.

웹 검색엔진의 필수요소는 다음과 같다

- 크롤링(crawling) : 웹페이지를 다운로드하고, 파싱하고 텍스트와 다른 페이지로의 링크를 추출하는 프로그램
- 인덱싱(indexing) : 검색어를 조회하고 해당 검색어를 포함한 페이지를 찾는데 필요한 자료구조
- 검색(retreval) : 인덱스에서 결과를 수집하고 검색어와 가장 관련된 페이지를 식별하는 방법

먼저 크롤러부터 시작해보자.크롤러의 목표는 일련의 웹페이지를 발견하고 다운로드하는 것이다. 

첫 단계로, 위키피디아 페이지를 읽고, 첫번째 링크를 찾고 다른 페이지로 링크를 따라가기를 반복하는 크롤러를 만들자. 

> 위키피디아 글의 본문에 있는 첫번쨰 소문자 링크를 클릭하고 이어지는 기사에서도 이 절차를 반복하면 보통 마지막에는 철학 글에 도달하게 된다

## HTML 파싱하기

웹 페이지를 다운로드할 때, 그 내용은 하이퍼텍스트마크업언어(HTML)로 작성되어있다. 예를 들어, 최소한의 HTML 문서는 아래와 같다.

```html
<!DOCKTYPE html>
<html>
    <head>
        <title>This is a title</title>
    </head>
    <body>
        <p>Hello World!</p>
    </body>
</html>
```

크롤러가 페이지를 다운로드하려면 HTML페이지를 파싱하여 본문과 링크를 추출해야 하는데, 이를 위해 HTML페이지를 다운로드하고 파싱하는 오픈소스 자바 라이브러리 jsoup 을 사용하겠다. HTML파싱의 결과는 본문과 태그같은 문서 요소를 담고 있는 문서객체모델(DOM)트리이다. 이 트리는 노드로 이루어진 연결자료구조이다.

루트라는 첫번째 노드는 <html> 태그이다. 여기에 포함된 두 노드 즉 <head> 와 <body> 에 대한 링크를 담고 있다. 이 노드들은 루트의 자식 노드이다. 

<head> 노드는 <title>이라는 자식 노드가 하나있고, <body>  노드는 <p> 라는 자식 노드가 하나 있다. 

![image-20220118125719756](https://raw.githubusercontent.com/yeonnex/image-server/main/img/image-20220118125719756.png)

각 노드는 자식 노드에 대한 링크를 포함한다. 또한 각 노드는 부모 노드에 대한 링크도 포함하고 있어서 트리를 위아래로 탐색할 수 있다.

## jsoup 사용하기

```java
public class MyParsing {
    public static void main(String[] args) throws IOException {
        String url = "https://en.wikipedia.org/wiki/Java_(programming_language)";
        // Download document and parsing
        Connection conn = Jsoup.connect(url);
        Document doc = conn.get();

        // Select content and extract paragraphs
        Element content = doc.getElementById("mw-content-text");
        Elements paragraphs = content.select("p");
        System.out.println(paragraphs);

    }
}
```

Jsoup.connect 메서드는 String 타입의 URL을 인자로 받아 웹서버에 접속한다. get 메서드는 HTML을 다운로드하여 파싱하고, DOM트리를 나타내는 Document객체를 반환한다.

Document객체는 트리를 탐색하고 노드를 선택하는 메서드를 제공한다. 

가장 중요한 클래스는 Element와 Elements, Node이다. 

Node 클래스는 DOM트리에서 노드를 의미한다. Node 하위 클래스에는 Element등이 있다. Elements클래스는 Element 객체의 컬렉션이다. Elements 클래스는 ArrayList 클래스를 확장한다.

## DOM트리 - 깊이 우선 탐색

트리를 탐색하는 방법은 응용 방법에 따라 몇가지가 있다. 먼저 깊이 우선 탐색부터! DFS는 트리의 루트에서 시작하여 첫번째 자식 노드를 선택한다. 자식이 자식을 가지고 있다면 첫번째 자식을 다시 선택한다. 자식이 없는 노드에 도착하면 부모 노드로 거슬러 올라가고, 부모 노드에 다음 자식이 있다면 그쪽으로 이동한다. 다음 자식이 없다면 다시 거슬러 올라간다. 루트의 마짐작 노드까지 탐색하면 종료한다.

DFS를 구현하는 방법에는 재귀적 방법과 반복적 방법 두가지가 있다. 

### 재귀적 방법

```java
private static void recursiveDFS(Node node) {
		if (node instanceof TextNode) {
			System.out.print(node);
		}
		for (Node child: node.childNodes()) {
			recursiveDFS(child);
		}
	}
```

이 코드에서는 자식 노드를 탐색하기에 앞서 각 TextNode의 내용을 출력하므로 전위순회에 해당한다. 재귀적 호출을 하면 recursiveDFS 메서드는 호출스택(call stack)을 사용하여 올바른 순서로 자식 노드를 처리한다. 대안으롱 스택 자료구조를 사용하여 스스로 노드를 추적할 수도 있다. 이렇게 하면 재귀 호출을 하지 않고 반복적으로 트리를 탐색할 수 있다.

## 스택

반복문을 사용하는 DFS를 공부하기에 앞서, 스택 자료구조에 대해 알아보자. 

## 반복적 DFS

```java
private static void iterativeDFS(Node root) {
		Deque<Node> stack = new ArrayDeque<Node>();
		stack.push(root);

		// if the stack is empty, we're done
		while (!stack.isEmpty()) {

			// otherwise pop the next Node off the stack
			Node node = stack.pop();
			if (node instanceof TextNode) {
				System.out.print(node);
			}

			// push the children onto the stack in reverse order
			List<Node> nodes = new ArrayList<Node>(node.childNodes());
			Collections.reverse(nodes);
			
			for (Node child: nodes) {
				stack.push(child);
			}
		}
	}
```



